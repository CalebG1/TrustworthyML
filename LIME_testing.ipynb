{"cells":[{"cell_type":"code","execution_count":10,"id":"a55f523c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a55f523c","outputId":"0abff587-d6b4-4090-a3e2-9224dcbdbaef","executionInfo":{"status":"ok","timestamp":1714405877956,"user_tz":240,"elapsed":22651,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-wgufvkqr\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-wgufvkqr\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.17.1+cu121)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->clip==1.0) (12.4.127)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (2.24.0)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.17.1+cu121)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2023.12.25)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.66.2)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.20.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.1.99)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (3.20.3)\n","Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.9.16)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9.0->open_clip_torch) (12.4.127)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->open_clip_torch) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"]}],"source":["!pip install git+https://github.com/openai/CLIP.git\n","!pip install open_clip_torch\n","!pip install sentence_transformers\n"]},{"cell_type":"code","execution_count":11,"id":"dd9ae37a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dd9ae37a","executionInfo":{"status":"ok","timestamp":1714405903050,"user_tz":240,"elapsed":13141,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}},"outputId":"3754baa2-0445-47cb-9b2f-2b4e564cd1f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":12,"id":"EsjqyTkQT-KF","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EsjqyTkQT-KF","executionInfo":{"status":"ok","timestamp":1714405920623,"user_tz":240,"elapsed":14461,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}},"outputId":"ab79f3e0-133a-4ad4-9e1b-d795e5eb4b1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n","Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"]}],"source":["!pip install shap"]},{"cell_type":"code","execution_count":13,"id":"da9640c8","metadata":{"id":"da9640c8","executionInfo":{"status":"ok","timestamp":1714405920623,"user_tz":240,"elapsed":8,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":["import numpy as np\n","import shap\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow.keras.layers as L\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import Model\n","#from kaggle_datasets import KaggleDatasets\n","from sklearn.model_selection import KFold\n","#from classification_models.tfkeras import Classifiers\n","import torch\n","import open_clip\n","import cv2\n","from sentence_transformers import util\n","from PIL import Image"]},{"cell_type":"code","execution_count":14,"id":"a7128f17","metadata":{"id":"a7128f17","executionInfo":{"status":"ok","timestamp":1714405920623,"user_tz":240,"elapsed":6,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":["orig_prompt = 'a lamp with flowers'"]},{"cell_type":"markdown","id":"dba66db3","metadata":{"id":"dba66db3"},"source":["sub prompts:\n","\n","    \n","    a lamp\n","    with flowers\n","    lamp with\n","    a lamp flowers\n","    lamp with\n","    a lamp with\n","    lamp flowers\n","    lamp with flowers\n","    with lamp a flowers\n","    "]},{"cell_type":"markdown","id":"4c7cac84","metadata":{"id":"4c7cac84"},"source":["## Calculate similarities of each image with the original image"]},{"cell_type":"code","execution_count":15,"id":"c8ee1f00","metadata":{"id":"c8ee1f00","executionInfo":{"status":"ok","timestamp":1714405935130,"user_tz":240,"elapsed":14512,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":["\n","\n","# image processing model\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16-plus-240', pretrained=\"laion400m_e32\")\n","model.to(device)\n","def imageEncoder(img):\n","    img1 = Image.fromarray(img).convert('RGB')\n","    img1 = preprocess(img1).unsqueeze(0).to(device)\n","    img1 = model.encode_image(img1)\n","    return img1\n","def generateScore(image1, image2):\n","    test_img = cv2.imread(image1, cv2.IMREAD_UNCHANGED)\n","    data_img = cv2.imread(image2, cv2.IMREAD_UNCHANGED)\n","    img1 = imageEncoder(test_img)\n","    img2 = imageEncoder(data_img)\n","    cos_scores = util.pytorch_cos_sim(img1, img2)\n","    score = round(float(cos_scores[0][0])*100, 2)\n","    return score"]},{"cell_type":"code","execution_count":15,"id":"2ab3c3cb","metadata":{"id":"2ab3c3cb","executionInfo":{"status":"ok","timestamp":1714405935131,"user_tz":240,"elapsed":25,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"id":"d4527b12","metadata":{"id":"d4527b12","executionInfo":{"status":"ok","timestamp":1714405935131,"user_tz":240,"elapsed":24,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":["orig_image = 'a_lamp_with_flowers.jpg'\n","sub1 = 'a_lamp.jpg'\n","sub2 = 'a_lamp_flowers.jpg'\n","sub3 = 'with_flowers.jpg'"]},{"cell_type":"code","execution_count":17,"id":"a6666540","metadata":{"id":"a6666540","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714405940678,"user_tz":240,"elapsed":5570,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}},"outputId":"6d3423c2-e498-473e-ff1f-28afbe2a90bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity Score of the image from 'a lamp':  62.44\n"]}],"source":["print(f\"Similarity Score of the image from 'a lamp': \", round(generateScore(orig_image, sub1), 2))"]},{"cell_type":"code","execution_count":18,"id":"00b5fd01","metadata":{"id":"00b5fd01","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714405944772,"user_tz":240,"elapsed":4098,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}},"outputId":"403f84ab-e7b8-4d0c-c26a-240aabfd9590"},"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity Score of the image from 'a lamp flowers':  69.55\n"]}],"source":["print(f\"Similarity Score of the image from 'a lamp flowers': \", round(generateScore(orig_image, sub2), 2))"]},{"cell_type":"code","execution_count":null,"id":"WdfnsmKfV6LA","metadata":{"id":"WdfnsmKfV6LA"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":19,"id":"b0942f79","metadata":{"id":"b0942f79","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714405954176,"user_tz":240,"elapsed":5705,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}},"outputId":"c0cf8f2b-863e-4ea4-a0bd-cf3852ce017a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity Score of the image from 'with flowers':  47.72\n"]}],"source":["print(f\"Similarity Score of the image from 'with flowers': \", round(generateScore(orig_image, sub3), 2))"]},{"cell_type":"code","execution_count":19,"id":"f4d085e9","metadata":{"id":"f4d085e9","executionInfo":{"status":"ok","timestamp":1714405955328,"user_tz":240,"elapsed":121,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9b48fb38","metadata":{"id":"9b48fb38"},"source":["\n","## Calculate shap values of prompt on the basis of the similarity metrics"]},{"cell_type":"markdown","id":"cea1b018","metadata":{"id":"cea1b018"},"source":["## Using the Gradient Explainer:\n","Expected gradients combines ideas from Integrated Gradients, SHAP, and SmoothGrad into a single expected value equation. This allows an entire dataset to be used as the background distribution (as opposed to a single reference value) and allows local smoothing. If we approximate the model with a linear function between each background data sample and the current input to be explained, and we assume the input features are independent then expected gradients will compute approximate SHAP values. In the example below we have explained how the 7th intermediate layer of the VGG16 ImageNet model impacts the output probabilities."]},{"cell_type":"code","execution_count":19,"id":"a421af71","metadata":{"id":"a421af71","executionInfo":{"status":"ok","timestamp":1714405957001,"user_tz":240,"elapsed":169,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":19,"id":"113dff93","metadata":{"id":"113dff93","executionInfo":{"status":"ok","timestamp":1714405957130,"user_tz":240,"elapsed":2,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"8b3a8eee","metadata":{"id":"8b3a8eee"},"source":["## Kernel Expainer"]},{"cell_type":"markdown","id":"7854c3bd","metadata":{"id":"7854c3bd"},"source":["An implementation of Kernel SHAP, a model agnostic method to estimate SHAP values for any model. Because it makes no assumptions about the model type, KernelExplainer is slower than the other model type specific algorithms.\n","\n"]},{"cell_type":"code","execution_count":19,"id":"b3fd3bd4","metadata":{"id":"b3fd3bd4","executionInfo":{"status":"ok","timestamp":1714405958973,"user_tz":240,"elapsed":144,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"YblkP4_NW2oN","metadata":{"id":"YblkP4_NW2oN"},"source":["###LIME"]},{"cell_type":"code","execution_count":21,"id":"NAeBouEYwmJ5","metadata":{"id":"NAeBouEYwmJ5","executionInfo":{"status":"ok","timestamp":1714406007285,"user_tz":240,"elapsed":36922,"user":{"displayName":"Caleb Gupta","userId":"04664018243172297024"}}},"outputs":[],"source":["prompt = 'a lamp with flowers'\n","# Have\n","img = 'a_lamp_with_flowers.jpg'\n","\n","a_prompt = []\n","lamp_prompt = []\n","with_prompt = []\n","flowers_prompt = []\n","\n","# Have\n","parse1 = 'a_lamp_with.jpg'\n","score = generateScore(img, parse1)\n","a_prompt.append(score)\n","lamp_prompt.append(score)\n","with_prompt.append(score)\n","\n","# Have\n","parse2 = 'a_lamp_flowers.jpg'\n","score = generateScore(img, parse2)\n","a_prompt.append(score)\n","lamp_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have\n","parse3 = 'a_with_flowers.jpg'\n","score = generateScore(img, parse3)\n","a_prompt.append(score)\n","with_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have\n","parse4 = 'a_lamp.jpg'\n","score = generateScore(img, parse4)\n","a_prompt.append(score)\n","lamp_prompt.append(score)\n","\n","# Have\n","parse5 = 'a_with.jpg'\n","score = generateScore(img, parse5)\n","a_prompt.append(score)\n","with_prompt.append(score)\n","\n","# Have\n","parse6 = 'a_flowers.jpg'\n","score = generateScore(img, parse6)\n","a_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have (duplicated this one - not legit)\n","parse7 = 'a.jpg'\n","score = generateScore(img, parse7)\n","a_prompt.append(score)\n","\n","# Have\n","parse8 = 'lamp_with_flowers.jpg'\n","score = generateScore(img, parse8)\n","lamp_prompt.append(score)\n","with_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have\n","parse9 = 'lamp_with.jpg'\n","score = generateScore(img, parse9)\n","lamp_prompt.append(score)\n","with_prompt.append(score)\n","\n","# Have\n","parse10 = 'lamp_flowers.jpg'\n","score = generateScore(img, parse10)\n","lamp_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have\n","parse11 = 'lamp.jpg'\n","score = generateScore(img, parse11)\n","lamp_prompt.append(score)\n","\n","# Have\n","parse12 = 'with_flowers.jpg'\n","score = generateScore(img, parse12)\n","with_prompt.append(score)\n","flowers_prompt.append(score)\n","\n","# Have (duplicated this one - not legit)\n","parse13 = 'with.jpg'\n","score = generateScore(img, parse13)\n","with_prompt.append(score)\n","\n","parse14 = 'flowers.jpg'\n","score = generateScore(img, parse14)\n","flowers_prompt.append(score)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4-XvpSrpynZM","metadata":{"id":"4-XvpSrpynZM"},"outputs":[],"source":["a_prompt = sum(a_prompt)\n","lamp_prompt = sum(lamp_prompt)\n","with_prompt = sum(with_prompt)\n","flowers_prompt = sum(flowers_prompt)"]},{"cell_type":"code","execution_count":null,"id":"JcKaZJfWyVMZ","metadata":{"id":"JcKaZJfWyVMZ"},"outputs":[],"source":["print(\"A: \", a_prompt)\n","print(\"Lamp: \", lamp_prompt)\n","print(\"With: \", with_prompt)\n","print(\"Flowers\", flowers_prompt)"]},{"cell_type":"code","execution_count":null,"id":"7sAbfcxxymbc","metadata":{"id":"7sAbfcxxymbc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"gv-FpVV9W6Mu","metadata":{"id":"gv-FpVV9W6Mu"},"outputs":[],"source":["!pip install lime"]},{"cell_type":"code","execution_count":null,"id":"fnBabMwiW2Rs","metadata":{"id":"fnBabMwiW2Rs"},"outputs":[],"source":["import lime\n","import sklearn\n","import numpy as np\n","import sklearn\n","import sklearn.ensemble\n","import sklearn.metrics\n","from __future__ import print_function"]},{"cell_type":"code","execution_count":null,"id":"LAcJH2HZW1_V","metadata":{"id":"LAcJH2HZW1_V"},"outputs":[],"source":["from sklearn.datasets import fetch_20newsgroups\n","categories = ['alt.atheism', 'soc.religion.christian']\n","newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n","newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n","class_names = ['atheism', 'christian']"]},{"cell_type":"code","execution_count":null,"id":"nTcn7r3xXMx7","metadata":{"id":"nTcn7r3xXMx7"},"outputs":[],"source":["vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n","train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n","test_vectors = vectorizer.transform(newsgroups_test.data)"]},{"cell_type":"code","execution_count":null,"id":"rSvAFOxWXg0r","metadata":{"id":"rSvAFOxWXg0r"},"outputs":[],"source":["rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n","rf.fit(train_vectors, newsgroups_train.target)"]},{"cell_type":"code","execution_count":null,"id":"YcBOqvOnXi9n","metadata":{"id":"YcBOqvOnXi9n"},"outputs":[],"source":["pred = rf.predict(test_vectors)\n","sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')"]},{"cell_type":"markdown","id":"59TX0-o-XxsC","metadata":{"id":"59TX0-o-XxsC"},"source":["LIME Explanations"]},{"cell_type":"code","execution_count":null,"id":"27muXnPYXvjl","metadata":{"id":"27muXnPYXvjl"},"outputs":[],"source":["from lime import lime_text\n","from sklearn.pipeline import make_pipeline\n","c = make_pipeline(vectorizer, rf)\n","print(c.predict_proba([newsgroups_test.data[0]]))"]},{"cell_type":"code","execution_count":null,"id":"zUPySCghX2dA","metadata":{"id":"zUPySCghX2dA"},"outputs":[],"source":["from lime.lime_text import LimeTextExplainer\n","explainer = LimeTextExplainer(class_names=class_names)"]},{"cell_type":"code","execution_count":null,"id":"PtgaBVwOX6Hi","metadata":{"id":"PtgaBVwOX6Hi"},"outputs":[],"source":["idx = 83\n","exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n","print('Document id: %d' % idx)\n","print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n","print('True class: %s' % class_names[newsgroups_test.target[idx]])"]},{"cell_type":"code","execution_count":null,"id":"mcVK02VkX9XR","metadata":{"id":"mcVK02VkX9XR"},"outputs":[],"source":["exp.as_list()"]},{"cell_type":"code","execution_count":null,"id":"CY3Kd4GHbupX","metadata":{"id":"CY3Kd4GHbupX"},"outputs":[],"source":["print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n","tmp = test_vectors[idx].copy()\n","tmp[0,vectorizer.vocabulary_['Posting']] = 0\n","tmp[0,vectorizer.vocabulary_['Host']] = 0\n","print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n","print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])"]},{"cell_type":"code","execution_count":null,"id":"LJ09TgLPeEr5","metadata":{"id":"LJ09TgLPeEr5"},"outputs":[],"source":["print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n","tmp = test_vectors[idx].copy()\n","tmp[0,vectorizer.vocabulary_['Posting']] = 0\n","tmp[0,vectorizer.vocabulary_['Host']] = 0\n","print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n","print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])"]},{"cell_type":"code","execution_count":null,"id":"4hSKKBhfeO-s","metadata":{"id":"4hSKKBhfeO-s"},"outputs":[],"source":["%matplotlib inline\n","fig = exp.as_pyplot_figure()"]},{"cell_type":"code","execution_count":null,"id":"qMetCXxyejM_","metadata":{"id":"qMetCXxyejM_"},"outputs":[],"source":["exp.show_in_notebook(text=False)"]},{"cell_type":"code","execution_count":null,"id":"ve4-_yZMerc3","metadata":{"id":"ve4-_yZMerc3"},"outputs":[],"source":["exp.save_to_file('/tmp/oi.html')\n"]},{"cell_type":"code","execution_count":null,"id":"EiuAl3e9etHX","metadata":{"id":"EiuAl3e9etHX"},"outputs":[],"source":["exp.show_in_notebook(text=True)\n"]},{"cell_type":"code","execution_count":null,"id":"PzdlUUi6euqK","metadata":{"id":"PzdlUUi6euqK"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1YVFGyAiGNTfNrSNtiDadBZo8Pv-1tNzC","timestamp":1714155242574}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}